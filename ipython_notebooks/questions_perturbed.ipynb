{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-py39_helm-cpu-l-1-cpu-8gb-ram",
      "display_name": "Python in CPU-L-1-cpu-8Gb-Ram (env py39_helm)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "createdOn": 1732563506997,
    "customFields": {},
    "creator": "sibongile.toure@dataiku.com",
    "modifiedBy": "sibongile.toure@dataiku.com",
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nfrom helm.benchmark.augmentations.perturbation_description import PerturbationDescription\nfrom helm.benchmark.augmentations.perturbation import Perturbation, TextPerturbation\nimport helm.benchmark.augmentations.perturbation\nfrom helm.benchmark import augmentations\nfrom helm.common.general import match_case, ensure_file_downloaded\nfrom dataclasses import dataclass, replace\nimport json\nimport os\nfrom random import Random\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom helm.benchmark.runner import get_benchmark_output_path\nfrom typing import Dict, Optional, List\nimport re"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "FOLDER_ID \u003d \u0027eEsu0vuN\u0027\n\nfolder \u003d dataiku.Folder(FOLDER_ID)\nlist_files \u003d folder.list_paths_in_partition()\n#folder.file_path(list_files[0])\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "list_files"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "folder.get_download_stream(list_files[0])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with folder.get_download_stream(list_files[0]) as stream:\n    data \u003d stream.read()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DialectPerturbation(TextPerturbation):\n    \"\"\"Individual fairness perturbation for dialect.\"\"\"\n\n    \"\"\" Short unique identifier of the perturbation (e.g., extra_space) \"\"\"\n    name: str \u003d \"dialect\"\n\n    should_perturb_references: bool \u003d True\n\n    \"\"\" Output path to store external files and folders \"\"\"\n    OUTPUT_PATH \u003d os.path.join(get_benchmark_output_path(), \"perturbations\", name)\n\n    \"\"\" Dictionary mapping dialects to one another \"\"\"\n    SAE \u003d \"SAE\"\n    AAVE \u003d \"AAVE\"\n\n    \"\"\" Dictionary containing the URIs for the dialect mapping dictionaries\n\n    Keys are tuples of the form (source_class, target_class), such as\n    (\"SAE\", \"AAVE\"). Mapping dictionaries are from the sources listed below,\n    converted to JSON and stored in Google Cloud Storage.\n\n        (1) SAE to AAVE dictionary is from Ziems et al. (2022)\n\n                Paper: https://arxiv.org/abs/2204.03031\n                GitHub: https://github.com/GT-SALT/value/\n\n    \"\"\"\n    MAPPING_DICT_URIS \u003d {\n        (SAE, AAVE): (\n            \"https://storage.googleapis.com/crfm-helm-public/source_datasets/\"\n            \"augmentations/dialect_perturbation/SAE_to_AAVE_mapping.json\"\n        )\n    }\n\n    @dataclass(frozen\u003dTrue)\n    class Description(PerturbationDescription):\n        \"\"\"Description for the DialectPerturbation class.\"\"\"\n\n        prob: float \u003d 0.0\n        source_class: str \u003d \"\"\n        target_class: str \u003d \"\"\n        mapping_file_path: Optional[str] \u003d None\n\n    def __init__(self, prob: float, source_class: str, target_class: str, mapping_file_path: Optional[str] \u003d None):\n        \"\"\"Initialize the dialect perturbation.\n\n        If mapping_file_path is not provided, (source_class, target_class)\n        should be (\"SAE\", \"AAVE\").\n\n        Args:\n            prob: Probability of substituting a word in the original class with\n                a word in the target class given that a substitution is\n                available.\n            source_class: The source dialect that will be substituted with\n                the target dialect. Case-insensitive.\n            target_class: The target dialect.\n            mapping_file_path: The absolute path to a file containing the\n                word mappings from the source dialect to the target dialect in\n                a json format. The json dictionary must be of type\n                Dict[str, List[str]]. Otherwise, the default dictionary in\n                self.MAPPING_DICTS for the provided source and target classes\n                will be used, if available.\n        \"\"\"\n        self.output_path: str \u003d self.OUTPUT_PATH\n        Path(self.output_path).mkdir(parents\u003dTrue, exist_ok\u003dTrue)\n\n        # Assign parameters to instance variables\n        assert 0 \u003c\u003d prob \u003c\u003d 1\n        self.prob \u003d prob\n        self.source_class: str \u003d source_class.upper()\n        self.target_class: str \u003d target_class.upper()\n\n        if mapping_file_path:\n            self.mapping_file_path: str \u003d mapping_file_path\n        else:\n            self.mapping_file_path \u003d self.retrieve_mapping_dict()\n        self.mapping_dict: Dict[str, List[str]] \u003d self.load_mapping_dict()\n\n        # Pattern capturing any occurence of the given words in the text, surrounded by characters other than\n        # alphanumeric characters and \u0027-\u0027. We use re.escape since the words in our dictionary may\n        # contain special RegEx characters.\n        words \u003d [re.escape(w) for w in self.mapping_dict.keys()]\n        words_string \u003d \"|\".join(words)\n        self.pattern \u003d f\"[^\\\\w-]({words_string})[^\\\\w-]\"\n\n    @property\n    def description(self) -\u003e PerturbationDescription:\n        \"\"\"Return a perturbation description for this class.\"\"\"\n        return DialectPerturbation.Description(\n            name\u003dself.name,\n            fairness\u003dTrue,\n            prob\u003dself.prob,\n            source_class\u003dself.source_class,\n            target_class\u003dself.target_class,\n            mapping_file_path\u003dself.mapping_file_path,\n        )\n\n    def retrieve_mapping_dict(self) -\u003e str:\n        \"\"\"Download the mapping dict for self.source_class to self.target_class, if available.\"\"\"\n        mapping_tuple \u003d (self.source_class, self.target_class)\n        if mapping_tuple not in self.MAPPING_DICT_URIS:\n            msg \u003d f\"\"\"The mapping from the source class {self.source_class} to the\n                      target class {self.target_class} isn\u0027t available in {self.MAPPING_DICT_URIS}.\n                   \"\"\"\n            raise ValueError(msg)\n        file_name \u003d f\"{self.source_class}_to_{self.target_class}_mapping.json\"\n        target_file_path: str \u003d os.path.join(self.output_path, file_name)\n        ensure_file_downloaded(source_url\u003dself.MAPPING_DICT_URIS[mapping_tuple], target_path\u003dtarget_file_path)\n        return target_file_path\n\n    def load_mapping_dict(self) -\u003e Dict[str, List[str]]:\n        \"\"\"Load the mapping dict.\"\"\"\n        with open(self.mapping_file_path, \"r\") as f:\n            return json.load(f)\n\n    def perturb(self, text: str, rng: Random) -\u003e str:\n        \"\"\"Substitute the source dialect in text with the target dialect with probability self.prob.\"\"\"\n\n        # Substitution function\n        def sub_func(m: re.Match):\n            match_str \u003d m.group(0)  # The full match (e.g. \" With \", \" With,\", \" With.\")\n            word \u003d m.group(1)  # Captured group (e.g. \"With\")\n            if rng.uniform(0, 1) \u003c self.prob:\n                synonyms \u003d self.mapping_dict[word.lower()]\n                synonym \u003d rng.choice(synonyms)  # Synonym (e.g. \"wit\")\n                synonym \u003d match_case(word, synonym)  # Synoynm with matching case (e.g. \"Wit\")\n                match_str \u003d match_str.replace(\n                    word, synonym\n                )  # Synonym placed in the matching group (e.g. \" Wit \", \" Wit,\", \" Wit.\")\n            return match_str\n\n        # Execute the RegEx\n        return re.sub(self.pattern, sub_func, text, flags\u003dre.IGNORECASE)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TextPerturbation \u003d TextPerturbation"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_dict: Dict[str, List[str]] \u003d json.loads(data.decode(\u0027utf-8\u0027))\n\n# Pattern capturing any occurence of the given words in the text, surrounded by characters other than\n# alphanumeric characters and \u0027-\u0027. We use re.escape since the words in our dictionary may\n# contain special RegEx characters.\nwords \u003d [re.escape(w) for w in mapping_dict.keys()]\nwords_string \u003d \"|\".join(words)\npattern \u003d f\"[^\\\\w-]({words_string})[^\\\\w-]\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping \u003d f\"/local/projects/LLMBIASJOBSEARCHCHAT/resources/lib/SAE_to_AAVE_mapping.json\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def perturb(self, text: str, rng: Random) -\u003e str:\n        \"\"\"Substitute the source dialect in text with the target dialect with probability self.prob.\"\"\"\n\n        # Substitution function\n        def sub_func(m: re.Match):\n            match_str \u003d m.group(0)  # The full match (e.g. \" With \", \" With,\", \" With.\")\n            word \u003d m.group(1)  # Captured group (e.g. \"With\")\n            if rng.uniform(0, 1) \u003c self.prob:\n                synonyms \u003d self.mapping_dict[word.lower()]\n                synonym \u003d rng.choice(synonyms)  # Synonym (e.g. \"wit\")\n                synonym \u003d match_case(word, synonym)  # Synoynm with matching case (e.g. \"Wit\")\n                match_str \u003d match_str.replace(\n                    word, synonym\n                )  # Synonym placed in the matching group (e.g. \" Wit \", \" Wit,\", \" Wit.\")\n            return match_str\n\n        # Execute the RegEx\n        return re.sub(self.pattern, sub_func, text, flags\u003dre.IGNORECASE)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        " MAPPING_DICT_URIS \u003d {\n        (\"SAE\", \"AAVE\"): (\n           data.decode(\"UTF-8\")\n        )\n    }\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MAPPING_DICT_URIS.keys()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "OUTPUT_PATH \u003d os.path.join(get_benchmark_output_path(), \"perturbations\", \"dialect\")\noutput_path \u003d OUTPUT_PATH\nPath(output_path).mkdir(parents\u003dTrue, exist_ok\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_class \u003d \u0027SAE\u0027\ntarget_class \u003d \"AAVE\"\nmapping_tuple \u003d (\u0027SAE\u0027,\u0027AAVE\u0027)\nif mapping_tuple not in MAPPING_DICT_URIS:\n    msg \u003d f\"\"\"The mapping from the source class {source_class} to the\n              target class {target_class} isn\u0027t available in {MAPPING_DICT_URIS}.\n           \"\"\"\n    raise ValueError(msg)\nfile_name \u003d f\"{source_class}_to_{target_class}_mapping.json\"\ntarget_file_path: str \u003d os.path.join(output_path, file_name)\n#ensure_file_downloaded(source_url\u003dMAPPING_DICT_URIS[mapping_tuple], target_path\u003dtarget_file_path)\n# return target_file_path"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\"/local/projects/LLMBIASJOBSEARCHCHAT/resources/lib/SAE_to_AAVE_mapping.json\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path \u003d os.getcwd()\nproject_name \u003d dataiku.get_custom_variables()[\"projectKey\"]\ndip_home \u003d dataiku.get_custom_variables()[\"dip.home\"]\nlibraries_path \u003d os.path.join(dip_home, \u0027config/projects/\u0027 + project_name + \u0027/resources/lib\u0027)\nprint(libraries_path)\nprint(os.listdir(\u0027lib/project/\u0027))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "/data/dataiku/datadir/jupyter-run/dku-workdirs/LLMBIASJOBSEARCHCHAT/VALUE9d9d688b-dataiku_user/project-python-libs/LLMBIASJOBSEARCHCHAT/python"
      ],
      "outputs": []
    }
  ]
}